{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qlp8TMCwqzju"
   },
   "source": [
    "# 確率と確率分布\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 条件付き確率\n",
    "\n",
    "事象の確率を、他の事象が起こったことを前提にして求めることを条件付き確率(conditional probability)という。\n",
    "もちろん、それぞれの事象が独立であれば、条件付き確率は単純にその事象の確率(の積)で表現できるが、一般の場合は必ずしも事象が独立であるとは限らない。\n",
    "\n",
    "例えば、$A$と$B$という2つの事象があるとき、$A$が起こったという条件の下で$B$が起こる確率は、$P(B|A)$と表される。このとき、$P(B|A)$は$P(A)$と$P(B)$の積ではなく、$A$が起こったときの$B$の起こりやすさを考慮した確率である。\n",
    "\n",
    "例としてある集団の50%が身長160cm以上であるとする。一方、この集団は50%が60kg以上の体重を持つとする。\n",
    "このとき、ランダムに選んだ人が身長160cm以上である確率($P(A)$としよう)は50%であり、体重60kg以上である確率$P(B)$も50%である。\n",
    "\n",
    "もし、身長と体重が完全に独立であれば、身長160cm以上で体重60kg以上である確率$P(A, B)$は$P(A) \\times P(B) = 0.5 \\times 0.5 = 0.25$となる。\n",
    "しかし、身長と体重は正の相関を持つことが多く、実際の$P(A, B)$は0.25よりも大きくなることが一般的でろう。\n",
    "\n",
    "このような場合、$P(A,B) \\neq P(A) \\times P(B)$となる。\n",
    "このとき、条件付き確率は次のように定義される。\n",
    "\n",
    "$$\n",
    "P(B|A) = \\frac{P(A,B)}{P(A)}\n",
    "$$\n",
    "\n",
    "この式は、$A$が起こったときの$B$の起こりやすさを表している。\n",
    "同様に、$P(A|B)$は次のように定義される\n",
    "\n",
    "$$\n",
    "P(A|B) = \\frac{P(A,B)}{P(B)}\n",
    "$$\n",
    "\n",
    "このように、条件付き確率は事象の依存関係を考慮して確率を計算するための重要な概念である。\n",
    "\n",
    "### ベイズの定理\n",
    "\n",
    "ベイズの定理(Bayes' theorem)は、条件付き確率を用いて事象の確率を更新するための重要な法則である。\n",
    "ベイズの定理は、次のように表される。\n",
    "\n",
    "`````{admonition} 定義: ベイズの定理\n",
    ":class: tip\n",
    "\n",
    "$$\n",
    "P(A|B) = \\frac{P(B|A) P(A)}{P(B)}\n",
    "$$\n",
    "\n",
    "`````\n",
    "\n",
    "この式は、事象$B$が起こったときに事象$A$が起こる確率を、事象$A$が起こったときの事象$B$の確率と、事象$A$の確率、および事象$B$の確率を用いて計算する方法を示している。\n",
    "なんのことはない、これは条件付き確率の定義そのものである。\n",
    "\n",
    "一方で、ベイズの定理の有用性を示すために、医療分野での応用を例に考えてみよう。\n",
    "\n",
    "ある病気の検査があり、その検査は病気にかかっている人の90%を正しく検出し、病気にかかっていない人の95%を正しく陰性と判定するものとする。\n",
    "\n",
    "このとき、検査結果が陽性であった場合に実際に病気にかかっている確率を求めることができる。\n",
    "ここで、次のような情報が与えられているとする。\n",
    "\n",
    "- 病気にかかっている人の割合（事前確率）: $P(A) = 0.01$（1%）\n",
    "- 病気が検査で陽性と判定される確率（事後確率）: $P(B|A) = 0.9$（病気にかかっている人の90%が陽性と判定される; 真陽性）\n",
    "- 病気にかかっていない人が陽性と判定される確率: $P(B|\\neg A) = 0.05$（病気にかかっていない人の5%が陽性と判定される; 偽陽性）\n",
    "- 検査が陽性である確率: $P(B) = P(B|A) P(A) + P(B|\\neg A) P(\\neg A)$\n",
    "\n",
    "したがって $A$は「病気にかかっている」という事象、$B$は「検査が陽性である」という事象に対応している。\n",
    "\n",
    "このとき、ベイズの定理を用いて、検査結果が陽性であった場合に実際に病気にかかっている確率$P(A|B)$を求めることができる。\n",
    "\n",
    "$$\n",
    "P(A|B) = \\frac{P(B|A) P(A)}{P(B)} = \\frac{0.9 \\times 0.01}{0.9 \\times 0.01 + 0.05 \\times 0.99}\n",
    " \\approx 0.154\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 確率密度関数\n",
    "\n",
    "上では、事象が離散的に起こる場合を考えた。\n",
    "以下では、実数値を取る連続型確率変数(continuous random variable)について考えることにする。\n",
    "\n",
    "関数$f: \\mathbb{R}^D \\to \\mathbb{R}$が確率密度関数(probability density function; pdf)であるとは、次を満たすことをいう。\n",
    "\n",
    "1. $f(\\mathbf{x}) \\geq 0$ である。\n",
    "2. 全ての値に対する$f$の積分は1である。\n",
    "\n",
    "$$\n",
    "\\int_{\\mathbb{R}^D} f(\\mathbf{x}) \\, d\\mathbf{x} = 1\n",
    "$$\n",
    "\n",
    "ここから、連続型確率変数$X$が\n",
    "\n",
    "$$\n",
    "P( a \\leq X \\leq b ) = \\int_{a}^{b} f(x) \\, dx\n",
    "$$\n",
    "\n",
    "を満たすことがわかる。確率変数$X$が微小区間$[x, x+dx]$に入る確率は$\\simeq f(x)dx$であることから、$f(x)$が確率密度と呼ばれることも理解できる。\n",
    "\n",
    "連続型確率変数$X$の累積分布関数(cumulative distribution function; cdf)は、次のように定義される。\n",
    "\n",
    "$$\n",
    "F_X(\\mathbf{x}) = P(X_1 \\leq x_1, X_2 \\leq x_2, \\ldots, X_D \\leq x_D) = \\int_{-\\infty}^{x_1} \\int_{-\\infty}^{x_2} \\cdots \\int_{-\\infty}^{x_D} f(\\mathbf{x}) \\, dx_1 \\, dx_2 \\cdots dx_D\n",
    "$$\n",
    "\n",
    "\n",
    "次に、確率変数$X$の期待値(expectation)と分散(variance)を定義する。\n",
    "\n",
    "期待値は、確率変数$X$の取り得る値にその確率を重み付けして合計したもので、次のように定義される。\n",
    "\n",
    "$$\n",
    "E[X] = \\int_{-\\infty}^{\\infty} x f(x) \\, dx\n",
    "$$\n",
    "\n",
    "分散は、確率変数$X$の値が期待値からどれだけ散らばっているかを示す指標で、次のように定義される。\n",
    "\n",
    "$$\n",
    "\\text{Var}[X] = E[(X - E[X])^2] = \\int_{-\\infty}^{\\infty} (x - E[X])^2 f(x) \\, dx\n",
    "$$\n",
    "\n",
    "確率密度関数を明示する $E_f[X]$といった表記もあるが、ここでは単に$E[X]$と書くことにした。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ガウス分布\n",
    "\n",
    "ガウス分布(Gaussian distribution)は、確率密度関数が次の形を持つ確率分布である。\n",
    "単変量の場合と多変量の場合をそれぞれ定義しておく:\n",
    "\n",
    "`````{admonition} 定義: ガウス分布/正規分布\n",
    ":class: tip\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "f(x) & = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp\\left(-\\frac{(x - \\mu)^2}{2 \\sigma^2}\\right) \\\\\n",
    "f(\\mathbf{x}) & = \\frac{1}{\\sqrt{ (2\\pi)^D |\\Sigma|}} \\exp\\left(-\\frac{1}{2} (\\mathbf{x} - \\boldsymbol{\\mu})^T \\Sigma^{-1} (\\mathbf{x} - \\boldsymbol{\\mu})\\right) \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "`````\n",
    "\n",
    "\n",
    "\n",
    "指数関数の前にある係数は、確率密度関数が正規化されていることを保証するためのもので、ガウス分布を全空間で積分したときに１になるようになっている。\n",
    "1変数の場合のガウス積分の簡単な証明を与えておこう。\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "I &\\equiv \\int_{-\\infty}^{\\infty} e^{(-\\alpha x^2)} dx \\\\\n",
    "I^2 & = \\left( \\int_{-\\infty}^{\\infty} e^{-\\alpha x^2} dx \\right) \\left( \\int_{-\\infty}^{\\infty} e^{-\\alpha y^2} dy \\right) \\\\\n",
    "& = \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} e^{-\\alpha (x^2 + y^2)} dx dy \\\\\n",
    "& = \\int_{0}^{2\\pi} \\int_{0}^{\\infty} e^{-\\alpha r^2} r dr d\\theta \\\\\n",
    "& = 2\\pi \\left[ -\\frac{1}{2\\alpha} e^{-\\alpha r^2} \\right]_{0}^{\\infty} \\\\\n",
    "I & = \\sqrt{\\frac{\\pi}{\\alpha}} \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "$x=r \\cos \\theta, y=r \\sin \\theta$と置換して、極座標に変換した。Jacobianは$r$である。\n",
    "$\\alpha=1/(2\\sigma^2)$と置換すると、ガウス分布の正規化定数が得られる。\n",
    "\n",
    "変数を２つに分けて、それらの **同時分布(joint distribution)** がガウス分布であるとみなすこともできる。\n",
    "\n",
    "$$\n",
    "p(\\mathbf{x}, \\mathbf{y}) = \\mathcal{N}\\left(\n",
    "    \\begin{bmatrix}\n",
    "        \\mathbf{\\mu}_x \\\\\n",
    "        \\mathbf{\\mu}_y\n",
    "    \\end{bmatrix},\n",
    "    \\begin{bmatrix}\n",
    "        \\Sigma_{xx} & \\Sigma_{xy} \\\\\n",
    "        \\Sigma_{yx} & \\Sigma_{yy}\n",
    "    \\end{bmatrix}\n",
    "\\right) \n",
    "$$\n",
    "\n",
    "このとき**周辺分布(marginal distribution)**(特定の変数の積分を取ることで得られる分布)と条件付き分布もまたガウス分布になる性質がある。$\\mathbf{y}$について周辺化した分布は、\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\int d\\mathbf{y} p(\\mathbf{x}, \\mathbf{y}) \n",
    "& = \\mathcal{N}\\left( \\mathbf{\\mu}_{x}, \\Sigma_{xx} \\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "p(\\mathbf{x} | \\mathbf{y}) & = \\mathcal{N}\\left(\n",
    "    \\mathbf{\\mu}_{x|y},\n",
    "    \\Sigma_{x|y}\\right) \\\\\n",
    "\\mathbf{\\mu}_{x|y} & = \\mathbf{\\mu}_x + \\Sigma_{xy} \\Sigma_{yy}^{-1} (\\mathbf{y} - \\mathbf{\\mu}_y) \\\\\n",
    "\\Sigma_{x|y} & = \\Sigma_{xx} - \\Sigma_{xy} \\Sigma_{yy}^{-1} \\Sigma_{yx}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "以下では、条件分布の式の導出を紹介しよう:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ある行列$M$の部分行列が以下のように書けるとき\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "M & = \\left( \n",
    "\\begin{matrix}\n",
    "A & B \\\\\n",
    "C & D\n",
    "\\end{matrix}\n",
    "\\right)^{-1} \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "$$\n",
    "S \\equiv (A - B D^{-1} C)^{-1}\n",
    "$$\n",
    "\n",
    "で定義される行列$S$を用いて、$M$は以下のように表される:\n",
    "\n",
    "$$\n",
    "M = \\begin{pmatrix}\n",
    "S & -S B D^{-1} \\\\\n",
    "-D^{-1} C S & D^{-1} + D^{-1} C S B D^{-1}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "なお、$S^{-1}$は行列$M$のSchur補行列(Schur complement)と呼ばれる。\n",
    "\n",
    "上記の関係を用いて、共分散行列の逆行列を、分割したそれぞれの部分行列の逆行列で表現することにする。\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\Sigma^{-1} & \\equiv\n",
    "\\left( \n",
    "\\begin{matrix}\n",
    "\\Sigma_{xx} & \\Sigma_{xy} \\\\\n",
    "\\Sigma_{yx} & \\Sigma_{yy}\n",
    "\\end{matrix}\n",
    "\\right)^{-1} \\equiv \\begin{pmatrix}\n",
    "\\Lambda_{xx} & \\Lambda_{xy} \\\\\n",
    "\\Lambda_{yx} & \\Lambda_{yy}\n",
    "\\end{pmatrix} \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "共分散行列の逆行列を精度行列(precision matrix)と呼び、$\\Lambda$で表す慣例に倣った。\n",
    "\n",
    "確率分布に係る係数等は一旦忘れて、条件付き確率分布のexponential関数の中身を見ていく。\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\log P(\\mathbf{x}, \\mathbf{y}) &= -\\frac{1}{2} (\\mathbf{x} - \\boldsymbol{\\mu}_x)^T \\Lambda_{xx} (\\mathbf{x} - \\boldsymbol{\\mu}_x) -\\frac{1}{2} (\\mathbf{x} - \\boldsymbol{\\mu}_x)^T \\Lambda_{xy} (\\mathbf{y} - \\boldsymbol{\\mu}_y) \n",
    "-\\frac{1}{2} (\\mathbf{y} - \\boldsymbol{\\mu}_y)^T \\Lambda_{yx} (\\mathbf{x} - \\boldsymbol{\\mu}_x) \n",
    "-\\frac{1}{2} (\\mathbf{y} - \\boldsymbol{\\mu}_y)^T \\Lambda_{yy} (\\mathbf{y} - \\boldsymbol{\\mu}_y) + \\text{const.} \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "$\\mathbf{x}$に関する1・2次の項をまとめよう。\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "-\\frac{1}{2} \\mathbf{x}^T \\Lambda_{xx} \\mathbf{x} \n",
    "+ \\mathbf{x}^T (\\Lambda_{xx} \\boldsymbol{\\mu}_x - \\Lambda_{xy} (\\mathbf{y} - \\boldsymbol{\\mu}_y) )\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "ここで、$\\Lambda_{xy} = \\Lambda_{yx}^T$であることを用いた。\n",
    "\n",
    "さらに、\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\Lambda_{xx} &= (\\Sigma_{xx} - \\Sigma_{xy} \\Sigma_{yy}^{-1} \\Sigma_{yx})^{-1} = \\Sigma_{x|y}^{-1}\\\\\n",
    "\\Lambda_{xy} &= -\\Sigma_{x|y}^{-1} \\Sigma_{xy} \\Sigma_{yy}^{-1}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "から、\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\log P(\\mathbf{x} | \\mathbf{y}) &= -\\frac{1}{2} (\\mathbf{x} - \\boldsymbol{\\mu}_{x|y})^T \\Sigma_{x|y}^{-1} (\\mathbf{x} - \\boldsymbol{\\mu}_{x|y}) + \\text{const.}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "となる。正規化すると、条件確率が上のガウス分布になることがわかる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ガウス分布と機械学習の関係\n",
    "\n",
    "機械学習分野において、ガウス分布は非常に重要な役割を果たす。\n",
    "全てを列挙することはできないが、幾つか代表的な例を挙げておく。\n",
    "\n",
    "- **線形回帰**: 線形回帰では、目的変数がガウス分布に従うと仮定することが多い。これは、誤差項がガウス分布に従うと仮定することで、線形モデルのパラメータを推定するだけでなく予測の信頼区間(不確実性)を計算できる。\n",
    "- **ガウス過程**: ガウス過程は、関数の分布を多次元正規分布で表現する手法であり、非線形回帰や分類問題において強力なツールとなる。ガウス過程は、データ点間の相関を考慮し、予測の不確実性を定量化することができ、ベイズ最適化などメタ的なアプローチにおいても利用される。\n",
    "- **混合ガウス分布**: 混合ガウス分布は、複数のガウス分布の線形結合であり、クラスタリングや密度推定に利用される。特に、Gaussian Mixture Model (GMM)は、データが複数の異なるガウス分布から生成されていると仮定し、各クラスタのパラメータを推定するために使用される。\n",
    "- **変分オートエンコーダ**: 変分オートエンコーダ(VAE)は、潜在変数モデルの一種であり、潜在変数がガウス分布に従うと仮定することで、データの生成過程を学習することが多い。\n",
    "- **拡散モデル**: 拡散モデルは、データの生成過程を逆拡散過程としてモデル化する手法であり、特に画像生成タスクにおいて注目されている。拡散モデルは、データにノイズを加えながら生成過程を学習し、最終的に高品質なサンプルを生成することができる。\n",
    "\n",
    "上記のうちのいくつかは、この資料でも説明してあるので適宜参照のこと。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 確率分布のベイズ推定\n",
    "\n",
    "2つの確率変数の同時分布を $p(\\mathbf{x}, \\mathbf{y})$、\n",
    "$p(\\mathbf{x}), p(\\mathbf{y})$ はそれぞれの確率変数の周辺分布と呼ぶ。\n",
    "\n",
    "確率の和の規則により、\n",
    "\n",
    "$$\n",
    "p(\\mathbf{x}) = \\int p(\\mathbf{x}, \\mathbf{y}) d\\mathbf{y}\n",
    "$$\n",
    "\n",
    "$$\n",
    "p(\\mathbf{y}) = \\int p(\\mathbf{x}, \\mathbf{y}) d\\mathbf{x}\n",
    "$$\n",
    "\n",
    "が成り立つ。離散的な場合は積分を和に置き換えればよい。\n",
    "\n",
    "また積の規則と呼ばれる法則は、同時分布と条件付き分布を結びつける:\n",
    "\n",
    "$$\n",
    "p(\\mathbf{x}, \\mathbf{y}) = p(\\mathbf{x} | \\mathbf{y}) p(\\mathbf{y}) = p(\\mathbf{y} | \\mathbf{x}) p(\\mathbf{x})\n",
    "$$\n",
    "\n",
    "ここから確率分布に対するベイズの定理が導かれる:\n",
    "\n",
    "$$\n",
    "p(\\mathbf{x} | \\mathbf{y}) = \\frac{p(\\mathbf{y} | \\mathbf{x}) p(\\mathbf{x})}{p(\\mathbf{y})}\n",
    "$$\n",
    "\n",
    "特に、$p(\\mathbf{x})$を事前分布(prior distribution)、$p(\\mathbf{y} | \\mathbf{x})$を尤度(likelihood)、$p(\\mathbf{x} | \\mathbf{y})$を事後分布(posterior distribution)と呼ぶ。\n",
    "\n",
    "確率変数を$x, y$とかくと、なんとなく等価・類似性のある量を２つ並べたように見えるが、もう少し機械学習の文脈に即した例を考えてみよう。\n",
    "\n",
    "いま何らかの現象やデータを説明することを目的に何らかのパラメータを持つモデル(ニューラルネットワークなど)を考え、\n",
    "さらにそのモデルのパラメータを$\\mathbf{\\theta}$という変数で表すことにする。\n",
    "このとき、入力データを$\\mathbf{x}$、出力データを$\\mathbf{y}$とし、幾つかのデータ点 $D = \\{(\\mathbf{x}_i, \\mathbf{y}_i)\\}_{i=1}^N$が得られていたとする。\n",
    "\n",
    "決められたデータセットに対して、最適なパラメータ$\\mathbf{\\theta}$を求めることが最適化問題の主要な目的であるが、\n",
    "いま考えているパラメータ$\\mathbf{\\theta}$がどのような値を取るかは不確実であり、確率変数として扱い分布を考えることもできる。\n",
    "その利点は、パラメータの不確実性を考慮に入れることで、より堅牢なモデルを構築できる点にある。\n",
    "さて、パラメータをある次元の特定の値ではなく、確率分布として扱うとき、次のような確率分布を考えることができる:\n",
    "\n",
    "$$\n",
    "p(\\mathbf{\\theta} | D) \\propto p(D | \\mathbf{\\theta}) p(\\mathbf{\\theta})\n",
    "$$\n",
    "\n",
    "左辺の$p(\\mathbf{\\theta} | D)$は、与えられたデータ$D$に基づくパラメータ$\\mathbf{\\theta}$の **事後分布(posterior)** を表す。\n",
    "右辺の$p(D | \\mathbf{\\theta})$は、パラメータ$\\mathbf{\\theta}$が与えられたときのデータ$D$の **尤度(likelihood)** を表し、$p(\\mathbf{\\theta})$はパラメータ$\\mathbf{\\theta}$の **事前分布(prior)** を表す。\n",
    "上記の比例関係の式から、パラメータに対する事前分布(事前知識や仮定)を、観測したデータに基づいて更新することができる。\n",
    "\n",
    "この文脈での尤度は、モデルがデータをどれだけよく説明できるかを示す指標であり、例えば、回帰問題であれば、観測データとモデルの平均二乗誤差を基にしたガウス分布を用いることも多い。\n",
    "\n",
    "$$\n",
    "p(D | \\mathbf{\\theta}) =C \\exp\\left(-\\frac{1}{2\\sigma^2} \\sum_{i=1}^N ||\\mathbf{y}_i - f(\\mathbf{x}_i; \\mathbf{\\theta})||^2 \\right)\n",
    "$$\n",
    "\n",
    "$C$は正規化定数である。\n",
    "\n",
    "また、上ではあえて比例関係$\\propto$を用いたが、分母にあたる$p(D)$はデータ$D$に関する正規化定数であり、パラメータ$\\mathbf{\\theta}$に依存しないため、事後分布を計算する際には無視できる(というより、計算が非常に難しいことが多い)ことによる。\n",
    "\n",
    "### $\\clubsuit$ 事後分布からのサンプリング\n",
    "\n",
    "事後分布に従うサンプルを生成するための方法としては、大別すると、近似推論(≒事後分布を性質の良い分布で近似する)と、MCMC(Markov Chain Monte Carlo; マルコフ連鎖モンテカルロ法)がある。\n",
    "事前分布及び尤度を性質の良い(共役分布; conjugate distribution)で選ぶと、事後分布も特定の分布族に属することが保証され、解析的に計算できる場合がある。\n",
    "近似推論では、こうした仮定を積極的に用いて、事後分布を計算しやすい分布で近似する。\n",
    "\n",
    "一方で、MCMCは、事後分布からのサンプルを生成するための確率的なアルゴリズムであり、事後分布の形状に関する仮定を必要としない。\n",
    "十分に多くのサンプルを\"きちんと\"生成できれば、事後分布を反映したサンプルを得ることができるが、実際にはサンプルの自己相関や収束性などに注意が必要であり、適切なアルゴリズムの選択とパラメータ設定が重要である。\n",
    "とくに多次元の分布からサンプルを生成する場合は、サンプルの自己相関が高くなりやすく、効率的なサンプリングが難しいことが多い。\n",
    "代表的なMCMCアルゴリズムには以下のようなものがある:\n",
    "\n",
    "- ギブスサンプリング(Gibbs sampling): 各変数を順番に更新する方法。条件付き分布が計算しやすい場合に有効。\n",
    "- メトロポリス・ヘイスティングス法(Metropolis-Hastings): 提案分布から新しいサンプルを生成し、受け入れるかどうかを確率的に決定する方法。提案分布の選択が重要。\n",
    "- ハミルトニアンモンテカルロ(Hamiltonian Monte Carlo; HMC): 物理学のハミルトン力学に基づく方法で、効率的に高次元空間を探索できる。勾配情報を利用するため、計算コストが高い場合がある。\n",
    "- レプリカ交換法(Replica Exchange MCMC; REMC) あるいはparallel tempering: 複数のマルコフ連鎖を異なるスケール因子(温度とも呼ばれる)で滑らかにしながら、レプリカ間でサンプルを交換する方法。多峰性分布のサンプリングに有効。\n",
    "- Affine Invariant MCMC: 複数のサンプルを同時に更新する方法で、アフィン変換に対して不変な性質を持つ。高次元空間でのサンプリングに適している。特に並列性が優れているほか、職人芸による提案分布の調整が不要であることが利点である。\n",
    "最初に提案されたのは Goodman & Weare (2010) で、天文学の分野で広く用いられているemcee (Foreman-Mackey et al., 2013) はこのアルゴリズムを実装したPythonライブラリである。\n",
    "\n",
    "筆者自身も、大学院生の頃〜大学教員になりたての頃に、物理学の文脈で近似推論/MCMCを用いた事後分布推定の研究を行っていた。\n",
    "その頃の経験則にはなるが、効率的なサンプリングを実現するにはデータの特性をよく理解し、適切なアルゴリズムとパラメータ設定を選ぶことが重要であり、試行錯誤や、適応的にパラメータを調整する手法が有効であると感じている。\n",
    "また、次元(≒パラメータ数)の小さい領域では、HMCが比較的安定して収束したサンプリングを与えることが多いが、勾配の計算が高コストになる状況ではあまり適さず、複数のworkerで並列に動作する方法、とくにAffine Invariant MCMCが有効であることが多い印象を持っている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多次元ガウス分布の最尤推定\n",
    "\n",
    "$$\n",
    "\\mathcal{N}(\\mathbf{x}; \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma}) \n",
    "= \\frac{1}{(2\\pi)^D |\\boldsymbol{\\Sigma}|}\n",
    "\\exp \\left( \n",
    "- \\frac{1}{2} (\\mathbf{x} - \\boldsymbol{\\mu})^T \\boldsymbol{\\Sigma}^{-1} (\\mathbf{x} - \\boldsymbol{\\mu})\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "多次元ガウス分布のパラメータを最尤推定することを考える。\n",
    "つまり、ガウス分布からのサンプル(とみなすデータ)が与えられたとき、そのガウス分布の平均ベクトルと共分散行列を推定することを考える。\n",
    "データが $\\{\\mathbf{x}_1, \\mathbf{x}_2, \\ldots, \\mathbf{x}_N\\}$ であり、各データ点 $\\mathbf{x}_i$ が $D$ 次元のベクトルであるとする。\n",
    "このとき、データの生成分布として尤もらしいガウス分布のパラメータ$\\boldsymbol{\\mu}$と$\\Sigma$を求めることが目的である。\n",
    "対数尤度を、以下のように与えよう:\n",
    "\n",
    "$$\n",
    "L(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})\n",
    "= \\log \\prod^N_{i=1} \\mathcal{N} (\\mathbf{x}_i; \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})\n",
    "$$\n",
    "\n",
    "結論から先に書くと、ガウス分布の平均ベクトルと共分散行列の最尤推定量はそれぞれ次のようになる:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\hat{\\boldsymbol{\\mu}} & = \\frac{1}{N} \\sum_{i=1}^{N} \\mathbf{x}_i \\\\\n",
    "\\hat{\\Sigma} &= \\frac{1}{N} \\sum_{i=1}^{N} (\\mathbf{x}_i - \\hat{\\boldsymbol{\\mu}})(\\mathbf{x}_i - \\hat{\\boldsymbol{\\mu}})^T\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "順番に示そう。まず対数尤度を少し整理しておこう。\n",
    "\n",
    "$$\n",
    "\\begin{align*}L(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})\n",
    "& = \\log \\prod^N_{i=1} \\mathcal{N} (\\mathbf{x}_i; \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma}) \\\\\n",
    "& = -\\frac{ND}{2} \\log(2\\pi) - \\frac{N}{2}\\log|\\boldsymbol{\\Sigma}| - \\frac{1}{2} \\sum^N_{i=1} (\\mathbf{x}_i - \\boldsymbol{\\mu})^T \\boldsymbol{\\Sigma}^{-1} (\\mathbf{x}_i - \\boldsymbol{\\mu})\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$\\boldsymbol{\\mu}$の最尤推定**\n",
    "\n",
    "上の対数尤度の表式の末尾の項だけを考えれば良い。\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial \\boldsymbol{\\mu}} \\left( \n",
    "   (\\mathbf{x}_i - \\boldsymbol{\\mu})^T \\boldsymbol{\\Sigma}^{-1} (\\mathbf{x}_i - \\boldsymbol{\\mu}) \n",
    "\\right) = -2 \\boldsymbol{\\Sigma}^{-1} (\\mathbf{x}_i - \\boldsymbol{\\mu})\n",
    "$$\n",
    "\n",
    "を用いると、\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\boldsymbol{\\mu}}\n",
    "= \\boldsymbol{\\Sigma}^{-1} \\sum_{i=1}^{N} (\\mathbf{x}_i - \\boldsymbol{\\mu})\n",
    "$$\n",
    "\n",
    "共分散行列は正則なので、\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "& \\sum_{i=1}^{N} (\\mathbf{x}_i - \\boldsymbol{\\mu}) = 0 \\\\\n",
    "& \\Leftrightarrow \\boldsymbol{\\mu} = \\frac{1}{N} \\sum_{i=1}^{N} \\mathbf{x}_i\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "となる。\n",
    "\n",
    "**$\\boldsymbol{\\Sigma}$の最尤推定**\n",
    "\n",
    "以下の2式を用いればよい:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial}{\\partial \\boldsymbol{\\Sigma}} \\log |\\boldsymbol{\\Sigma}| & = \\left(  \\boldsymbol{\\Sigma}^{-1} \\right)^T \\\\\n",
    "\\frac{\\partial}{\\partial \\boldsymbol{\\Sigma}} \\left( \\sum^N_{i=1} (\\mathbf{x}_i - \\boldsymbol{\\mu})^T \\boldsymbol{\\Sigma}^{-1} (\\mathbf{x}_i - \\boldsymbol{\\mu}) \\right)\n",
    "& = - \\left(\\boldsymbol{\\Sigma}^{-1}  \\sum^N_{i=1} (\\mathbf{x}_i - \\boldsymbol{\\mu})^T  (\\mathbf{x}_i - \\boldsymbol{\\mu}) \\boldsymbol{\\Sigma}^{-1} \\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "ここから、\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\boldsymbol{\\Sigma}}\n",
    "= \\frac{N}{2} \\left( \\boldsymbol{\\Sigma}^{-1} \\right)^T + \\frac{1}{2} \\left(\\boldsymbol{\\Sigma}^{-1} \\sum^N_{i=1} (\\mathbf{x}_i - \\boldsymbol{\\mu})^T  (\\mathbf{x}_i - \\boldsymbol{\\mu})  \\boldsymbol{\\Sigma}^{-1} \\right)^T = 0\n",
    "$$\n",
    "\n",
    "から、上の式が従う。\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Python_chapter_Bayesian_linear_regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
