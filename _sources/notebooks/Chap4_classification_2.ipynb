{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qlp8TMCwqzju"
      },
      "source": [
        "# 多クラス分類\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "この章では、一つ前の二値分類を拡張し、多クラス分類について説明する。\n",
        "\n",
        "多クラス分類とは、分類タスクにおいて、2つ以上のクラスに対して予測を行うことである。\n",
        "\n",
        "二項分類が2つのクラス（例：正/負、0/1）に対する予測だけを行うのに対し、\n",
        "多クラス分類は3つ以上の異なるクラスに対して予測を行う。手書き文字認識や画像分類など、多くの応用例がある。\n",
        "\n",
        "例えば手書き文字の画像を与えて、画像の中で描かれている数字が0~9のいずれかを判定する場合はクラスの数は１０になり、\n",
        "一般の写真を見せて写っているものが何か分類する際には、分類したい項目の数を指定する必要がある。\n",
        "したがって、クラスの数については一般に問題ごとに変わり得る。そこで、以下では、できるだけクラスの数を$N$と一般化して議論することにしよう。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \"多クラス\"の扱い方\n",
        "\n",
        "まずは、特定のデータについて、どのように\"多クラス\"を扱うかを考えてみよう。\n",
        "\n",
        "- **入力**: $D$次元のベクトル$\\boldsymbol{x} \\in \\mathbb{R}^D$とする。例えば画像データならピクセル値を並べたベクトルなどになる。\n",
        "- **クラス(またはカテゴリやラベル)**: 分類の候補。集合であることを明示して$\\mathcal{C} = \\{C_1,C_2,...,C_K\\}$と書くことにする。$K$は分類先のクラスの数。\n",
        "    >例えば果物について分類する場合、$\\mathcal{C}=\\{ \\mathrm{りんご},\\mathrm{みかん},\\mathrm{バナナ},...\\}$といったイメージ。\n",
        "- **出力**: $K$次元のベクトル$\\hat{\\boldsymbol{y}}$とする。$K$個のクラスそれぞれに対応する要素が、そのクラスに属する確率を表す。\n",
        "    >例えば、$K=3$の場合、$\\boldsymbol{y}=(0.2, 0.5, 0.3)$というベクトルは、3つのクラスそれぞれに対応する要素が、それぞれ0.2, 0.5, 0.3という確率を表す。この場合、0.5が最も大きいので、このデータは2番目のクラスに属すると予測される。\n",
        "\n",
        "以降では、データの真の分類を$y$と書き、何らかのモデルによる分類の予測には$\\hat{\\boldsymbol{y}}$という記号を使うことにする。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 線形多クラス分類\n",
        "\n",
        "線形二値分類を拡張して、線形多クラス分類を考えてみよう。\n",
        "\n",
        ":::{admonition} 線形多クラス分類の式 \n",
        ":class: important\n",
        "\n",
        "$$\n",
        "\\nonumber \\\\\n",
        "\\hat{y} = \\mathop{\\rm argmax}\\limits_{y \\in \\mathcal{C}} \\boldsymbol{w}_y^T \\boldsymbol{x} \n",
        "$$(eq:linear_multi_class)\n",
        ":::\n",
        "\n",
        "ここで、各クラス$y$に対応する重みベクトルを$\\boldsymbol{w}_y$とした。この式は、入力$\\boldsymbol{x}$に対して、各クラスに対応する重みベクトルとの内積を計算し、最大となるクラスを予測するというものである。\n",
        "\n",
        "線形二値分類の場合と同様、重み$\\boldsymbol{w}_y$は、そのクラスに属するデータを正しく分類できるように学習(調整)する。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## ソフトマックス回帰 (Softmax Regression)\n",
        "\n",
        "ソフトマックス回帰（または多項ロジスティック回帰）は、多クラス分類を直接的にモデリングする方法。\n",
        "\n",
        "この手法は一つの確率モデルを用いて、複数のクラスに対する確率を同時に推計する。\n",
        "\n",
        "ソフトマックス回帰は、ロジスティック回帰を多クラス分類に拡張したものとみなせる。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Importing necessary libraries\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Logistic Regression classifier with 'multinomial' option\n",
        "clf = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
        "\n",
        "# Fit the model\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = np.mean(y_pred == y_test)\n",
        "accuracy\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Python_chapter_Bayesian_linear_regression.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
